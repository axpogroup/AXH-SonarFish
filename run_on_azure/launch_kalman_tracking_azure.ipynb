{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "from azure.ai.ml import MLClient, Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "subscription = os.getenv(f\"subscription_id\")\n",
    "resource_group = os.getenv(f\"resource_group\")\n",
    "workspace = os.getenv(f\"workspace_name\")\n",
    "\n",
    "ml_client = MLClient(\n",
    "    AzureCliCredential(), \n",
    "    subscription, \n",
    "    resource_group, \n",
    "    workspace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant = 'lavey'\n",
    "sonar_location = 'passe3'\n",
    "date = \"2024-03-06\"\n",
    "datastore_name = 'workspaceblobstore'\n",
    "base_path_on_datastore = f'{plant}_videos/{sonar_location}/'\n",
    "base_intermediate_path_on_datastore = f'{plant}_tracking_intermediate_data/{sonar_location}/'\n",
    "base_output_path_on_datastore = f'{plant}_tracking_output_alternative_algo_settings/{sonar_location}/'\n",
    "path_on_datastore = f'{base_path_on_datastore}{date.replace(\"-\", \"/\")}'\n",
    "intermediate_path_on_datastore = f'{base_intermediate_path_on_datastore}{date.replace(\"-\", \"/\")}'\n",
    "output_path_on_datastore = f'{base_output_path_on_datastore}{date.replace(\"-\", \"/\")}'\n",
    "\n",
    "uri = f'azureml://subscriptions/{subscription}/resourcegroups/{resource_group}/workspaces/{workspace}/datastores/{datastore_name}/paths/'\n",
    "uri_input = f'{uri}{path_on_datastore}'\n",
    "uri_intermediate_data = f'{uri}{intermediate_path_on_datastore}'\n",
    "uri_output = f'{uri}{output_path_on_datastore}'\n",
    "# remove sanity_check from the uri_train_val_gt_data if doing sanity check\n",
    "uri_train_val_gt_data = f\"{uri}{plant}_classification/train_data/{sonar_location.replace('_sanity_check', '')}/\"\n",
    "classification_settings_file = f\"classification_settings_{plant}_{sonar_location.replace('_sanity_check', '')}.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all steps in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import load_component\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "\n",
    "run_tracking = load_component(source=\"./components/kalman_tracking/tracking.yml\")\n",
    "run_classification = load_component(source=\"./components/classification/classification.yml\")\n",
    "\n",
    "@pipeline(\n",
    "    compute=\"Standard-D1-v2\",\n",
    ")\n",
    "def tracking_all_steps(\n",
    "    input_videos_dir: Input(type=AssetTypes.URI_FOLDER), \n",
    "    train_val_gt_data_dir: Input(type=AssetTypes.URI_FOLDER),\n",
    "    classification_settings_file: str,\n",
    "    output_data_uri: str = None,\n",
    "    intermediate_data_uri: str = None,\n",
    "    log_level: str = \"INFO\",\n",
    "):\n",
    "    \n",
    "    tracking_results = run_tracking(\n",
    "        data=input_videos_dir,\n",
    "        tracking_config=\"kalman_tracking_settings.yaml\",\n",
    "    )\n",
    "    tracking_results.outputs.detections = Output(type=\"uri_folder\", path=intermediate_data_uri, mode=InputOutputModes.RW_MOUNT)\n",
    "    \n",
    "    classification_run_results = run_classification(\n",
    "        classification_settings_file=classification_settings_file,\n",
    "        train_val_gt_data_dir=train_val_gt_data_dir,\n",
    "        files_to_classify_dir=tracking_results.outputs.detections,\n",
    "        log_level=log_level,\n",
    "    )\n",
    "    classification_run_results.outputs.classified_detections_dir = Output(\n",
    "        type=\"uri_folder\",\n",
    "        path=output_data_uri,\n",
    "        mode=InputOutputModes.RW_MOUNT,\n",
    "    )\n",
    "    classification_run_results.compute = \"Standard-A4m-v2\"\n",
    "    \n",
    "    labeling_results = run_tracking(\n",
    "        data=input_videos_dir,\n",
    "        labels_dir=classification_run_results.outputs.classified_detections_dir,\n",
    "        tracking_config=\"annotate_video_settings.yaml\",\n",
    "    )\n",
    "    labeling_results.compute = \"Standard-D2\"\n",
    "\n",
    "    return {\"detections\": labeling_results.outputs.detections}\n",
    "\n",
    "\n",
    "@pipeline(\n",
    "    compute=\"Standard-D1-v2\",\n",
    ")\n",
    "def tracking_all_steps_pre_labeling(\n",
    "    input_videos_dir: Input(type=AssetTypes.URI_FOLDER), \n",
    "    train_val_gt_data_dir: Input(type=AssetTypes.URI_FOLDER),\n",
    "    classification_settings_file: str,\n",
    "    output_data_uri: str = None,\n",
    "    intermediate_data_uri: str = None,\n",
    "    log_level: str = \"INFO\",\n",
    "):\n",
    "    \n",
    "    tracking_results = run_tracking(\n",
    "        data=input_videos_dir,\n",
    "        tracking_config=\"kalman_tracking_settings_pre_labeling.yaml\",\n",
    "    )\n",
    "    tracking_results.outputs.detections = Output(type=\"uri_folder\", path=intermediate_data_uri, mode=InputOutputModes.RW_MOUNT)\n",
    "    \n",
    "    classification_run_results = run_classification(\n",
    "        classification_settings_file=classification_settings_file,\n",
    "        train_val_gt_data_dir=train_val_gt_data_dir,\n",
    "        files_to_classify_dir=tracking_results.outputs.detections,\n",
    "        log_level=log_level,\n",
    "    )\n",
    "    classification_run_results.outputs.classified_detections_dir = Output(\n",
    "        type=\"uri_folder\",\n",
    "        path=output_data_uri,\n",
    "        mode=InputOutputModes.RW_MOUNT,\n",
    "    )\n",
    "    classification_run_results.compute = \"Standard-A4m-v2\"\n",
    "    \n",
    "    labeling_results = run_tracking(\n",
    "        data=input_videos_dir,\n",
    "        labels_dir=classification_run_results.outputs.classified_detections_dir,\n",
    "        tracking_config=\"annotate_video_settings.yaml\",\n",
    "    )\n",
    "    labeling_results.compute = \"Standard-D2\"\n",
    "\n",
    "    return {\"detections\": labeling_results.outputs.detections}\n",
    "    \n",
    "\n",
    "@pipeline(\n",
    "    compute=\"Standard-D1-v2\",\n",
    ")\n",
    "def tracking_base_steps(\n",
    "    input_data: Input(type=AssetTypes.URI_FOLDER), \n",
    "    train_val_data: Input(type=AssetTypes.URI_FOLDER), \n",
    "    train_val_gt_data: Input(type=AssetTypes.URI_FOLDER),\n",
    "    classification_settings_file: str,\n",
    "    indermediate_data_uri: str = None,\n",
    "    log_level: str = \"INFO\",\n",
    "):\n",
    "    \n",
    "    tracking_results = run_tracking(\n",
    "        data=input_data,\n",
    "        tracking_config=\"kalman_tracking_settings.yaml\",\n",
    "    )\n",
    "    tracking_results.outputs.detections = Output(type=\"uri_folder\", path=indermediate_data_uri, mode=InputOutputModes.RW_MOUNT)\n",
    "    \n",
    "    classification_run_results = run_classification(\n",
    "        train_val_data=train_val_data,\n",
    "        train_val_gt_data=train_val_gt_data,\n",
    "        files_to_classify=tracking_results.outputs.detections,\n",
    "        log_level=log_level,\n",
    "    )\n",
    "    classification_run_results.compute = \"Standard-A4m-v2\"\n",
    "    \n",
    "    return {\"detections\": classification_run_results.outputs.classified_detections_dir}\n",
    "\n",
    "\n",
    "@pipeline(\n",
    "    compute=\"Standard-D1-v2\",\n",
    ")\n",
    "def classification_and_labeling_videos(\n",
    "    input_videos_dir: Input(type=AssetTypes.URI_FOLDER),\n",
    "    train_val_gt_data_dir: Input(type=AssetTypes.URI_FOLDER),\n",
    "    classification_settings_file: str,\n",
    "    intermediate_data: Input(type=AssetTypes.URI_FOLDER),\n",
    "    output_data_uri: str = None,\n",
    "    log_level: str = \"INFO\",\n",
    "):\n",
    "    \n",
    "    classification_run_results = run_classification(\n",
    "        classification_settings_file=classification_settings_file,\n",
    "        train_val_gt_data_dir=train_val_gt_data_dir,\n",
    "        files_to_classify_dir=intermediate_data,\n",
    "        log_level=log_level,\n",
    "    )\n",
    "    classification_run_results.outputs.classified_detections_dir = Output(\n",
    "        type=\"uri_folder\",\n",
    "        path=output_data_uri,\n",
    "        mode=InputOutputModes.RW_MOUNT,\n",
    "    )\n",
    "    classification_run_results.compute = \"Standard-A4m-v2\"\n",
    "    \n",
    "    labeling_results = run_tracking(\n",
    "        data=input_videos_dir,\n",
    "        labels_dir=classification_run_results.outputs.classified_detections_dir,\n",
    "        tracking_config=\"annotate_video_settings.yaml\",\n",
    "    )\n",
    "    labeling_results.compute = \"Standard-D2\"\n",
    "\n",
    "    return {\"detections\": labeling_results.outputs.detections}\n",
    "\n",
    "@pipeline(\n",
    "    compute=\"Standard-D2\",\n",
    ")\n",
    "def labeling_videos(\n",
    "    input_data: Input(type=AssetTypes.URI_FOLDER),\n",
    "    labels_dir: Input(type=AssetTypes.URI_FOLDER),\n",
    "):\n",
    "    labeling_results = run_tracking(\n",
    "        data=input_data,\n",
    "        labels_dir=labels_dir,\n",
    "        tracking_config=\"annotate_video_settings.yaml\",\n",
    "    )\n",
    "\n",
    "    return {\"detections\": labeling_results.outputs.detections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from azure.ai.ml import load_component\n",
    "\n",
    "start_at = \"tracking_pre_labeling\"\n",
    "\n",
    "if start_at == \"tracking\":\n",
    "    pipeline_job = tracking_all_steps(\n",
    "        classification_settings_file=classification_settings_file,\n",
    "        input_videos_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_input, mode=InputOutputModes.RO_MOUNT),\n",
    "        train_val_gt_data_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_train_val_gt_data, mode=InputOutputModes.RO_MOUNT),\n",
    "        intermediate_data_uri=uri_intermediate_data,\n",
    "        output_data_uri=uri_output,\n",
    "    )\n",
    "    pipeline_job.outputs.detections = Output(type=\"uri_folder\", path=uri_output, mode=InputOutputModes.RW_MOUNT)\n",
    "    pipeline_job.tags = {\"date\": date}\n",
    "elif start_at == \"tracking_pre_labeling\":\n",
    "    pipeline_job = tracking_all_steps_pre_labeling(\n",
    "        classification_settings_file=classification_settings_file,\n",
    "        input_videos_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_input, mode=InputOutputModes.RO_MOUNT),\n",
    "        train_val_gt_data_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_train_val_gt_data, mode=InputOutputModes.RO_MOUNT),\n",
    "        intermediate_data_uri=uri_intermediate_data,\n",
    "        output_data_uri=uri_output,\n",
    "    )\n",
    "    pipeline_job.outputs.detections = Output(type=\"uri_folder\", path=uri_output, mode=InputOutputModes.RW_MOUNT)\n",
    "    pipeline_job.tags = {\"date\": date}\n",
    "elif start_at == \"classification\":\n",
    "    pipeline_job = classification_and_labeling_videos(\n",
    "        input_videos_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_input, mode=InputOutputModes.DOWNLOAD),\n",
    "        train_val_gt_data_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_train_val_gt_data, mode=InputOutputModes.DOWNLOAD),\n",
    "        indermediate_data_uri=uri_intermediate_data,\n",
    "    )\n",
    "    pipeline_job.outputs.classified_detection_videos_dir = Output(type=\"uri_folder\", path=uri_output, mode=InputOutputModes.RW_MOUNT)\n",
    "    pipeline_job.tags = {\"date\": date}\n",
    "elif start_at == \"labeling_videos\":\n",
    "    pipeline_job = labeling_videos(\n",
    "        input_data=Input(type=AssetTypes.URI_FOLDER, path=uri_input, mode=InputOutputModes.DOWNLOAD),\n",
    "        labels_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_output, mode=InputOutputModes.DOWNLOAD),\n",
    "    )\n",
    "    pipeline_job.outputs.detections = Output(type=\"uri_folder\", path=uri_output, mode=InputOutputModes.RW_MOUNT)\n",
    "    pipeline_job.tags = {\"date\": date}\n",
    "\n",
    "pipeline_job.display_name = f\"{plant}-{sonar_location}-{start_at}-{date}\"\n",
    "\n",
    "# copy library files to job source directory temporarily\n",
    "pth_cls = './components/classification/src/analysis/classification_utils/'\n",
    "pth_masks = './components/classification/src/analysis/demo/'\n",
    "pth = './components/kalman_tracking/src/algorithm/'\n",
    "shutil.copytree('../analysis/classification_utils/', pth_cls, dirs_exist_ok=True)\n",
    "shutil.copytree('../analysis/demo/', pth_masks, dirs_exist_ok=True)\n",
    "shutil.copytree('../algorithm/', pth, dirs_exist_ok=True)\n",
    "\n",
    "pipeline_job_run = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=f\"track-and-classify-{plant}-{sonar_location}\"\n",
    ")\n",
    "\n",
    "shutil.rmtree(pth)\n",
    "shutil.rmtree(pth_masks)\n",
    "shutil.rmtree(pth_cls)\n",
    "pipeline_job_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Jobs for every day of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "\n",
    "def generate_paths(\n",
    "    datastore_uri: str,\n",
    "    day_list: list,\n",
    "    date_separator: str = '/',\n",
    ") -> tuple[str, str, str, str]:\n",
    "    for date_str in day_list:\n",
    "        date_str = date_str.replace('-', date_separator)\n",
    "        path_on_datastore = f'{datastore_uri}{base_path_on_datastore}{date_str}/'\n",
    "        intermediate_path_on_datastore = f'{datastore_uri}{base_intermediate_path_on_datastore}{date_str}/'\n",
    "        output_path_on_datastore = f'{datastore_uri}{base_output_path_on_datastore}{date_str}/'\n",
    "\n",
    "        yield path_on_datastore, intermediate_path_on_datastore, output_path_on_datastore, date_str\n",
    "\n",
    "\n",
    "def generate_paths_for_range(\n",
    "        datastore_uri: str,\n",
    "        start_date: Optional[str] = None,\n",
    "        end_date: Optional[str] = None,\n",
    "        date_separator: str = '/',\n",
    "    ) -> tuple[str, str, str, str]:\n",
    "    if start_date:\n",
    "        dates = pd.date_range(start=start_date, end=end_date)\n",
    "    else:\n",
    "        dates = ['_test']\n",
    "        \n",
    "    dates = [date.strftime(f'%Y{date_separator}%m{date_separator}%d') for date in dates]\n",
    "    return generate_paths(datastore_uri, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for a range of dates\n",
    "date_generator = generate_paths_for_range(uri, '2024-03-07', '2024-04-30')\n",
    "# for a list of dates\n",
    "# failed_jobs = ['2024-03-08', '2024-03-07', '2024-04-26', '2024-04-25', '2024-04-23', '2024-04-21', \n",
    "#  '2024-04-20', '2024-04-19', '2024-04-18', '2024-04-17', '2024-04-16', '2024-04-15', \n",
    "#  '2024-04-13', '2024-04-12', '2024-04-11', '2024-04-10', '2024-04-09', '2024-04-08', \n",
    "#  '2024-04-07', '2024-04-05', '2024-04-04', '2024-04-03', '2024-04-02']\n",
    "# canceled_jobs = ['2024-03-05', '2024-03-04', '2024-03-10', '2024-03-09', '2024-03-06', '2024-04-30', \n",
    "#  '2024-04-29', '2024-04-28', '2024-04-27', '2024-04-24', '2024-04-22', '2024-04-14', \n",
    "#  '2024-04-06', '2024-04-01']\n",
    "# date_generator = generate_paths(uri, canceled_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submitted job with tags: {'date': '2024/03/07', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/08', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/09', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/10', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/11', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/12', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/13', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/14', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/15', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/16', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/17', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/18', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/19', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/20', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/21', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/22', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/23', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/24', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/25', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/26', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/27', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/28', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/29', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/30', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/03/31', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/01', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/02', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/03', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/04', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/05', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/06', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/07', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/08', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/09', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/10', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/11', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/12', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/13', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/14', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/15', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/16', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/17', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/18', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/19', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/20', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/21', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/22', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/23', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/24', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/25', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/26', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/27', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/28', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/29', 'location': 'lavey-passe3'}\n",
      "submitted job with tags: {'date': '2024/04/30', 'location': 'lavey-passe3'}\n"
     ]
    }
   ],
   "source": [
    "# copy library files to job source directory temporarily\n",
    "pth_cls = './components/classification/src/analysis/classification_utils/'\n",
    "pth_masks = './components/classification/src/analysis/demo/'\n",
    "pth = './components/kalman_tracking/src/algorithm/'\n",
    "shutil.copytree('../analysis/classification_utils/', pth_cls, dirs_exist_ok=True)\n",
    "shutil.copytree('../analysis/demo/', pth_masks, dirs_exist_ok=True)\n",
    "shutil.copytree('../algorithm/', pth, dirs_exist_ok=True)\n",
    "\n",
    "start_at = \"tracking_pre_labeling\"\n",
    "\n",
    "for raw_videos_dir_path, intermediate_path_on_datastore, output_path_on_datastore, date_str in date_generator:\n",
    "    if start_at == \"tracking\":\n",
    "        pipeline_job = tracking_all_steps(\n",
    "                classification_settings_file=classification_settings_file,\n",
    "                input_videos_dir=Input(type=AssetTypes.URI_FOLDER, path=raw_videos_dir_path, mode=InputOutputModes.RO_MOUNT),\n",
    "                train_val_gt_data_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_train_val_gt_data, mode=InputOutputModes.RO_MOUNT),\n",
    "                intermediate_data_uri=intermediate_path_on_datastore,\n",
    "                output_data_uri=output_path_on_datastore,\n",
    "            )\n",
    "    elif start_at == \"tracking_pre_labeling\":\n",
    "        pipeline_job = tracking_all_steps_pre_labeling(\n",
    "                classification_settings_file=classification_settings_file,\n",
    "                input_videos_dir=Input(type=AssetTypes.URI_FOLDER, path=raw_videos_dir_path, mode=InputOutputModes.RO_MOUNT),\n",
    "                train_val_gt_data_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_train_val_gt_data, mode=InputOutputModes.RO_MOUNT),\n",
    "                intermediate_data_uri=intermediate_path_on_datastore,\n",
    "                output_data_uri=output_path_on_datastore,\n",
    "            )\n",
    "    elif start_at == \"classification\":\n",
    "        pipeline_job = classification_and_labeling_videos(\n",
    "                classification_settings_file=classification_settings_file,\n",
    "                input_videos_dir=Input(type=AssetTypes.URI_FOLDER, path=raw_videos_dir_path, mode=InputOutputModes.RO_MOUNT),\n",
    "                train_val_gt_data_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_train_val_gt_data, mode=InputOutputModes.RO_MOUNT),\n",
    "                intermediate_data=Input(type=AssetTypes.URI_FOLDER, path=intermediate_path_on_datastore, mode=InputOutputModes.DOWNLOAD),\n",
    "                output_data_uri=output_path_on_datastore,\n",
    "        )\n",
    "    elif start_at == \"labeling_videos\":\n",
    "        pipeline_job = labeling_videos(\n",
    "            input_data=Input(type=AssetTypes.URI_FOLDER, path=raw_videos_dir_path, mode=InputOutputModes.DOWNLOAD),\n",
    "            labels_dir=Input(type=AssetTypes.URI_FOLDER, path=output_path_on_datastore, mode=InputOutputModes.DOWNLOAD),\n",
    "        )\n",
    "    pipeline_job.outputs.detections = Output(type=\"uri_folder\", path=output_path_on_datastore, mode=InputOutputModes.RW_MOUNT)\n",
    "    pipeline_job.tags = {\"date\": date_str, \"location\": f\"{plant}-{sonar_location}\"}\n",
    "    pipeline_job.display_name = f\"{plant}-{sonar_location}-{date_str}\"\n",
    "    \n",
    "    pipeline_job_run = ml_client.jobs.create_or_update(\n",
    "        pipeline_job, \n",
    "        experiment_name=f\"{plant}-{sonar_location}-{start_at}\",\n",
    "    )\n",
    "    print(f'submitted job with tags: {pipeline_job_run.tags}')\n",
    "    \n",
    "shutil.rmtree(pth)\n",
    "shutil.rmtree(pth_masks)\n",
    "shutil.rmtree(pth_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
