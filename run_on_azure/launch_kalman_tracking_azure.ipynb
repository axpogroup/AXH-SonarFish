{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "from azure.ai.ml import MLClient, command, Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "subscription = os.getenv(f\"subscription_id\")\n",
    "resource_group = os.getenv(f\"resource_group\")\n",
    "workspace = os.getenv(f\"workspace_name\")\n",
    "\n",
    "ml_client = MLClient(\n",
    "    AzureCliCredential(), \n",
    "    subscription, \n",
    "    resource_group, \n",
    "    workspace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant = 'lavey'\n",
    "sonar_location = 'Tourelle'\n",
    "datastore_name = 'workspaceblobstore'\n",
    "path_on_datastore = f'{plant}_videos/{sonar_location}/2024-04-02/'\n",
    "intermediate_path_on_datastore = f'{plant}_tracking_intermediate_data/{sonar_location}/2024-04-02/'\n",
    "output_path_on_datastore = f'{plant}_tracking_output/{sonar_location}/2024-04-02/'\n",
    "classification_settings_file = 'classification_settings_lavey_tourelle.yaml'\n",
    "\n",
    "# long-form Datastore uri format:\n",
    "uri = f'azureml://subscriptions/{subscription}/resourcegroups/{resource_group}/workspaces/{workspace}/datastores/{datastore_name}/paths/'\n",
    "uri_input = f'{uri}{path_on_datastore}'\n",
    "uri_intermediate_data = f'{uri}{intermediate_path_on_datastore}'\n",
    "uri_output = f'{uri}{output_path_on_datastore}'\n",
    "uri_train_val_gt_data = f'{uri}{plant}_classification/train_data/{sonar_location}/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all steps in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import load_component\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "\n",
    "run_tracking = load_component(source=\"./components/kalman_tracking/tracking.yml\")\n",
    "run_classification = load_component(source=\"./components/classification/classification.yml\")\n",
    "\n",
    "@pipeline(\n",
    "    compute=\"Standard-D1-v2\",\n",
    ")\n",
    "def tracking_all_steps(\n",
    "    input_videos_dir: Input(type=AssetTypes.URI_FOLDER), \n",
    "    train_val_gt_data_dir: Input(type=AssetTypes.URI_FOLDER),\n",
    "    classification_settings_file: str,\n",
    "    output_data_uri: str = None,\n",
    "    intermediate_data_uri: str = None,\n",
    "    log_level: str = \"INFO\",\n",
    "):\n",
    "    \n",
    "    tracking_results = run_tracking(\n",
    "        data=input_videos_dir,\n",
    "        tracking_config=\"kalman_tracking_settings.yaml\",\n",
    "    )\n",
    "    tracking_results.outputs.detections = Output(type=\"uri_folder\", path=intermediate_data_uri, mode=InputOutputModes.RW_MOUNT)\n",
    "    \n",
    "    classification_run_results = run_classification(\n",
    "        classification_settings_file=classification_settings_file,\n",
    "        train_val_gt_data_dir=train_val_gt_data_dir,\n",
    "        files_to_classify_dir=tracking_results.outputs.detections,\n",
    "        log_level=log_level,\n",
    "    )\n",
    "    classification_run_results.outputs.classified_detections_dir = Output(\n",
    "        type=\"uri_folder\",\n",
    "        path=output_data_uri,\n",
    "        mode=InputOutputModes.RW_MOUNT,\n",
    "    )\n",
    "    classification_run_results.compute = \"Standard-A2m-v2\"\n",
    "    \n",
    "    labeling_results = run_tracking(\n",
    "        data=input_videos_dir,\n",
    "        labels_dir=classification_run_results.outputs.classified_detections_dir,\n",
    "        tracking_config=\"annotate_video_settings.yaml\",\n",
    "    )\n",
    "\n",
    "    return {\"detections\": labeling_results.outputs.detections}\n",
    "    \n",
    "\n",
    "@pipeline(\n",
    "    compute=\"Standard-D1-v2\",\n",
    ")\n",
    "def tracking_base_steps(\n",
    "    input_data: Input(type=AssetTypes.URI_FOLDER), \n",
    "    train_val_data: Input(type=AssetTypes.URI_FOLDER), \n",
    "    train_val_gt_data: Input(type=AssetTypes.URI_FOLDER),\n",
    "    classification_settings_file: str,\n",
    "    indermediate_data_uri: str = None,\n",
    "    log_level: str = \"INFO\",\n",
    "):\n",
    "    \n",
    "    tracking_results = run_tracking(\n",
    "        data=input_data,\n",
    "        tracking_config=\"kalman_tracking_settings.yaml\",\n",
    "    )\n",
    "    tracking_results.outputs.detections = Output(type=\"uri_folder\", path=indermediate_data_uri, mode=InputOutputModes.RW_MOUNT)\n",
    "    \n",
    "    classification_run_results = run_classification(\n",
    "        train_val_data=train_val_data,\n",
    "        train_val_gt_data=train_val_gt_data,\n",
    "        files_to_classify=tracking_results.outputs.detections,\n",
    "        log_level=log_level,\n",
    "    )\n",
    "    classification_run_results.compute = \"Standard-A2m-v2\"\n",
    "    \n",
    "    return {\"detections\": classification_run_results.outputs.classified_detections_dir}\n",
    "\n",
    "# TODO: adapt the other two pipelines\n",
    "@pipeline(\n",
    "    compute=\"Standard-D1-v2\",\n",
    ")\n",
    "def classification_and_labeling_videos(\n",
    "    input_data: Input(type=AssetTypes.URI_FOLDER),\n",
    "    train_val_data: Input(type=AssetTypes.URI_FOLDER), \n",
    "    train_val_gt_data: Input(type=AssetTypes.URI_FOLDER),\n",
    "    intermediate_data: Input(type=AssetTypes.URI_FOLDER),\n",
    "    output_data_uri: str = None,\n",
    "    log_level: str = \"INFO\",\n",
    "):\n",
    "    \n",
    "    classification_run_results = run_classification(\n",
    "        train_val_data=train_val_data,\n",
    "        train_val_gt_data=train_val_gt_data,\n",
    "        files_to_classify=intermediate_data,\n",
    "        log_level=log_level,\n",
    "    )\n",
    "    classification_run_results.outputs.classified_detections_dir = Output(\n",
    "        type=\"uri_folder\",\n",
    "        path=output_data_uri,\n",
    "        mode=InputOutputModes.RW_MOUNT,\n",
    "    )\n",
    "    classification_run_results.compute = \"Standard-A2m-v2\"\n",
    "    \n",
    "    labeling_results = run_tracking(\n",
    "        data=input_data,\n",
    "        labels_dir=classification_run_results.outputs.classified_detections_dir,\n",
    "        tracking_config=\"annotate_video_settings.yaml\",\n",
    "    )\n",
    "\n",
    "    return {\"detections\": labeling_results.outputs.detections}\n",
    "\n",
    "@pipeline(\n",
    "    compute=\"Standard-D1-v2\",\n",
    ")\n",
    "def labeling_videos(\n",
    "    input_data: Input(type=AssetTypes.URI_FOLDER),\n",
    "    labels_dir: Input(type=AssetTypes.URI_FOLDER),\n",
    "):\n",
    "    labeling_results = run_tracking(\n",
    "        data=input_data,\n",
    "        labels_dir=labels_dir,\n",
    "        tracking_config=\"annotate_video_settings.yaml\",\n",
    "    )\n",
    "\n",
    "    return {\"detections\": labeling_results.outputs.detections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>pipeline-track-all-steps</td><td>goofy_foot_sd1qd31v3j</td><td>pipeline</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/goofy_foot_sd1qd31v3j?wsid=/subscriptions/e9eedc4b-b891-4bf4-a924-06b9c6e0f02f/resourcegroups/axsa-lab-appl-fishsonar-rg/workspaces/axsa-lab-appl-fishsonar-ml&amp;tid=8619c67c-945a-48ae-8e77-35b1b71c9b98\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {'input_videos_dir': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x754fae58f550>, 'train_val_gt_data_dir': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x754fae58d360>, 'classification_settings_file': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x754fae58f460>, 'output_data_uri': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x754fae58cd30>, 'intermediate_data_uri': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x754fae58ea70>, 'log_level': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x754fae58f490>}, 'outputs': {'detections': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x754fae58f670>}, 'jobs': {}, 'component': PipelineComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/home/nicolaspelzmann/Documents/projects/MTA/AXH-SonarFish/run_on_azure', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x754fae58f430>, 'version': '1', 'schema': None, 'type': 'pipeline', 'display_name': 'tracking_all_steps', 'is_deterministic': None, 'inputs': {'input_videos_dir': {}, 'train_val_gt_data_dir': {}, 'classification_settings_file': {}, 'output_data_uri': {}, 'intermediate_data_uri': {}, 'log_level': {}}, 'outputs': {'detections': {}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'tracking_results': Command({'parameters': {}, 'init': False, 'name': 'tracking_results', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': '/home/nicolaspelzmann/Documents/projects/MTA/AXH-SonarFish/run_on_azure', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x754fae52cd60>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'tracking_config': 'kalman_tracking_settings.yaml', 'data': '${{parent.inputs.input_videos_dir}}'}, 'job_outputs': {'detections': {'type': 'uri_folder', 'path': '${{parent.inputs.intermediate_data_uri}}', 'mode': 'rw_mount'}}, 'inputs': {'tracking_config': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x754fae52f640>, 'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x754fae52f8b0>}, 'outputs': {'detections': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x754fadb81180>}, 'component': 'azureml_anonymous:1b4caf19-eab1-463b-834b-f3186b6ba718', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '6f232739-6cae-4455-93f6-3d802a323a2d', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'classification_run_results': Command({'parameters': {}, 'init': False, 'name': 'classification_run_results', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': '/home/nicolaspelzmann/Documents/projects/MTA/AXH-SonarFish/run_on_azure', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x754fae52ceb0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': 'Standard-A2m-v2', 'services': None, 'comment': None, 'job_inputs': {'classification_settings_file': '${{parent.inputs.classification_settings_file}}', 'train_val_gt_data_dir': '${{parent.inputs.train_val_gt_data_dir}}', 'files_to_classify_dir': '${{parent.jobs.tracking_results.outputs.detections}}', 'log_level': '${{parent.inputs.log_level}}'}, 'job_outputs': {'classified_detections_dir': {'type': 'uri_folder', 'path': '${{parent.inputs.output_data_uri}}', 'mode': 'rw_mount'}}, 'inputs': {'classification_settings_file': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x754fae52c910>, 'train_val_gt_data_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x754fae52fc10>, 'files_to_classify_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x754fae52cf10>, 'log_level': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x754fae52fa30>}, 'outputs': {'classified_detections_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x754fae52d600>}, 'component': 'azureml_anonymous:7bac6039-8b6f-409f-b61d-6928a802d803', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': 'b7e1a2d1-e2b4-4e78-ab86-7a018967e78a', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'labeling_results': Command({'parameters': {}, 'init': False, 'name': 'labeling_results', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': '/home/nicolaspelzmann/Documents/projects/MTA/AXH-SonarFish/run_on_azure', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x754fae52cc40>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'tracking_config': 'annotate_video_settings.yaml', 'data': '${{parent.inputs.input_videos_dir}}', 'labels_dir': '${{parent.jobs.classification_run_results.outputs.classified_detections_dir}}'}, 'job_outputs': {'detections': '${{parent.outputs.detections}}'}, 'inputs': {'tracking_config': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x754fae58d690>, 'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x754fae58cee0>, 'labels_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x754fae58f7f0>}, 'outputs': {'detections': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x754fae52c430>}, 'component': 'azureml_anonymous:1b4caf19-eab1-463b-834b-f3186b6ba718', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '05aecdcc-f67d-4ceb-9037-454c48994b66', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False})}, 'job_types': {'command': 3}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 3}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'NotStarted', 'log_files': None, 'name': 'goofy_foot_sd1qd31v3j', 'description': None, 'tags': {'date': '2024-04-02'}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/axpogroup/AXH-SonarFish.git', 'mlflow.source.git.branch': 'feature/MDS-680/lavey-azureml-pipeline', 'mlflow.source.git.commit': '42b76bd8044af68da61d169e7c91cacfcbcec361', 'azureml.git.dirty': 'True'}, 'print_as_yaml': False, 'id': '/subscriptions/e9eedc4b-b891-4bf4-a924-06b9c6e0f02f/resourceGroups/axsa-lab-appl-fishsonar-rg/providers/Microsoft.MachineLearningServices/workspaces/axsa-lab-appl-fishsonar-ml/jobs/goofy_foot_sd1qd31v3j', 'Resource__source_path': '', 'base_path': '/home/nicolaspelzmann/Documents/projects/MTA/AXH-SonarFish/run_on_azure', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x754fae58f610>, 'serialize': <msrest.serialization.Serializer object at 0x754fae58e230>, 'display_name': 'tracking_all_steps', 'experiment_name': 'pipeline-track-all-steps', 'compute': 'Standard-D1-v2', 'services': {'Tracking': {'endpoint': 'azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/e9eedc4b-b891-4bf4-a924-06b9c6e0f02f/resourceGroups/axsa-lab-appl-fishsonar-rg/providers/Microsoft.MachineLearningServices/workspaces/axsa-lab-appl-fishsonar-ml?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/goofy_foot_sd1qd31v3j?wsid=/subscriptions/e9eedc4b-b891-4bf4-a924-06b9c6e0f02f/resourcegroups/axsa-lab-appl-fishsonar-rg/workspaces/axsa-lab-appl-fishsonar-ml&tid=8619c67c-945a-48ae-8e77-35b1b71c9b98', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "from azure.ai.ml import load_component\n",
    "\n",
    "generate_videos_with_detections = True\n",
    "\n",
    "\n",
    "if generate_videos_with_detections:\n",
    "    pipeline_job = tracking_all_steps(\n",
    "        classification_settings_file=classification_settings_file,\n",
    "        input_videos_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_input, mode=InputOutputModes.DOWNLOAD),\n",
    "        train_val_gt_data_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_train_val_gt_data, mode=InputOutputModes.DOWNLOAD),\n",
    "        intermediate_data_uri=uri_intermediate_data,\n",
    "        output_data_uri=uri_output,\n",
    "    )\n",
    "    pipeline_job.outputs.detections = Output(type=\"uri_folder\", path=uri_output, mode=InputOutputModes.RW_MOUNT)\n",
    "    pipeline_job.tags = {\"date\": \"2024-04-02\"}\n",
    "else:\n",
    "    pipeline_job = tracking_base_steps(\n",
    "        input_videos_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_input, mode=InputOutputModes.DOWNLOAD),\n",
    "        train_val_gt_data_dir=Input(type=AssetTypes.URI_FOLDER, path=uri_train_val_gt_data, mode=InputOutputModes.DOWNLOAD),\n",
    "        indermediate_data_uri=uri_intermediate_data,\n",
    "    )\n",
    "    pipeline_job.outputs.classified_detection_videos_dir = Output(type=\"uri_folder\", path=uri_output, mode=InputOutputModes.RW_MOUNT)\n",
    "    pipeline_job.tags = {\"date\": \"2023-03-28\"}\n",
    "\n",
    "# copy library files to job source directory temporarily\n",
    "pth_cls = './components/classification/src/analysis/classification_utils/'\n",
    "shutil.copytree('../analysis/classification_utils/', pth_cls, dirs_exist_ok=True)\n",
    "pth = './components/kalman_tracking/src/algorithm/'\n",
    "shutil.copytree('../algorithm/', pth, dirs_exist_ok=True)\n",
    "\n",
    "pipeline_job_run = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"pipeline-track-all-steps\"\n",
    ")\n",
    "\n",
    "shutil.rmtree(pth)\n",
    "shutil.rmtree(pth_cls)\n",
    "pipeline_job_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Jobs for every day of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "\n",
    "def generate_paths(\n",
    "    datastore_uri: str,\n",
    "    day_list: list,\n",
    "    base_path_on_datastore: str = 'stroppel_videos/',\n",
    "    base_intermediate_path_on_datastore: str = 'stroppel_tracking_intermediate_data_short_burn_in/',\n",
    "    base_output_path_on_datastore: str = 'stroppel_tracking_output_short_burn_in/',\n",
    ") -> tuple[str, str, str, str]:\n",
    "    for date_str in day_list:\n",
    "        # Create the paths for the current date\n",
    "        path_on_datastore = f'{datastore_uri}{base_path_on_datastore}{date_str}/'\n",
    "        intermediate_path_on_datastore = f'{datastore_uri}{base_intermediate_path_on_datastore}{date_str}/'\n",
    "        output_path_on_datastore = f'{datastore_uri}{base_output_path_on_datastore}{date_str}/'\n",
    "\n",
    "        yield path_on_datastore, intermediate_path_on_datastore, output_path_on_datastore, date_str\n",
    "\n",
    "\n",
    "def generate_paths_for_range(\n",
    "        datastore_uri: str,\n",
    "        start_date: Optional[str] = None,\n",
    "        end_date: Optional[str] = None,\n",
    "        base_path_on_datastore: str = 'stroppel_videos/',\n",
    "        base_intermediate_path_on_datastore: str = 'stroppel_tracking_intermediate_data_short_burn_in/',\n",
    "        base_output_path_on_datastore: str = 'stroppel_tracking_output_short_burn_in/',\n",
    "    ) -> tuple[str, str, str, str]:\n",
    "    if start_date:\n",
    "        dates = pd.date_range(start=start_date, end=end_date)\n",
    "    else:\n",
    "        dates = ['_test']\n",
    "        \n",
    "    dates = [date.strftime('%Y-%m-%d') for date in dates]\n",
    "    return generate_paths(datastore_uri, dates, base_path_on_datastore, base_intermediate_path_on_datastore, base_output_path_on_datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for a range of dates\n",
    "# start_date = '2023-06-19'\n",
    "# end_date = '2023-06-19'\n",
    "# date_generator = generate_paths_for_range(uri, start_date, end_date)\n",
    "# for a list of dates\n",
    "dates = ['2023-03-11', '2023-03-20', '2023-03-26', '2024-04-02']\n",
    "date_generator = generate_paths(uri, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submitted job with tags: {'date': '2023-03-29'}\n",
      "submitted job with tags: {'date': '2023-03-30'}\n",
      "submitted job with tags: {'date': '2023-03-31'}\n",
      "submitted job with tags: {'date': '2023-04-01'}\n",
      "submitted job with tags: {'date': '2023-04-02'}\n",
      "submitted job with tags: {'date': '2023-04-03'}\n",
      "submitted job with tags: {'date': '2023-04-04'}\n",
      "submitted job with tags: {'date': '2023-04-05'}\n",
      "submitted job with tags: {'date': '2023-04-06'}\n",
      "submitted job with tags: {'date': '2023-04-07'}\n",
      "submitted job with tags: {'date': '2023-04-08'}\n",
      "submitted job with tags: {'date': '2023-04-09'}\n",
      "submitted job with tags: {'date': '2023-04-10'}\n",
      "submitted job with tags: {'date': '2023-04-11'}\n",
      "submitted job with tags: {'date': '2023-04-12'}\n",
      "submitted job with tags: {'date': '2023-04-13'}\n",
      "submitted job with tags: {'date': '2023-04-14'}\n",
      "submitted job with tags: {'date': '2023-04-15'}\n",
      "submitted job with tags: {'date': '2023-04-16'}\n",
      "submitted job with tags: {'date': '2023-04-17'}\n",
      "submitted job with tags: {'date': '2023-04-18'}\n",
      "submitted job with tags: {'date': '2023-04-19'}\n",
      "submitted job with tags: {'date': '2023-04-20'}\n",
      "submitted job with tags: {'date': '2023-04-21'}\n",
      "submitted job with tags: {'date': '2023-04-22'}\n",
      "submitted job with tags: {'date': '2023-04-23'}\n",
      "submitted job with tags: {'date': '2023-04-24'}\n",
      "submitted job with tags: {'date': '2023-04-25'}\n",
      "submitted job with tags: {'date': '2023-04-26'}\n",
      "submitted job with tags: {'date': '2023-04-27'}\n",
      "submitted job with tags: {'date': '2023-04-28'}\n",
      "submitted job with tags: {'date': '2023-04-29'}\n",
      "submitted job with tags: {'date': '2023-04-30'}\n"
     ]
    }
   ],
   "source": [
    "# copy library files to job source directory temporarily\n",
    "pth_cls = './components/classification/src/analysis/classification_utils/'\n",
    "shutil.copytree('../analysis/classification_utils/', pth_cls, dirs_exist_ok=True)\n",
    "pth = './components/kalman_tracking/src/algorithm/'\n",
    "shutil.copytree('../algorithm/', pth, dirs_exist_ok=True)\n",
    "\n",
    "for raw_videos_dir_path, intermediate_path_on_datastore, output_path_on_datastore, date_str in date_generator:\n",
    "    pipeline_job = tracking_all_steps(\n",
    "        input_data=Input(type=AssetTypes.URI_FOLDER, path=raw_videos_dir_path, mode=InputOutputModes.DOWNLOAD),\n",
    "        train_val_data=Input(type=AssetTypes.URI_FOLDER, path=uri_train_val_data, mode=InputOutputModes.DOWNLOAD),\n",
    "        train_val_gt_data=Input(type=AssetTypes.URI_FOLDER, path=uri_train_val_gt_data, mode=InputOutputModes.DOWNLOAD),\n",
    "        indermediate_data_uri=intermediate_path_on_datastore,\n",
    "        output_data_uri=output_path_on_datastore,\n",
    "    )\n",
    "    pipeline_job.outputs.detections = Output(type=\"uri_folder\", path=output_path_on_datastore, mode=InputOutputModes.RW_MOUNT)\n",
    "    pipeline_job.tags = {\"date\": date_str, \"location\": \"{plant}-{sonar}\"}\n",
    "    pipeline_job.display_name = f\"{plant}-{sonar_location}-{date_str}\"\n",
    "    \n",
    "    pipeline_job_run = ml_client.jobs.create_or_update(\n",
    "        pipeline_job, \n",
    "        experiment_name=f\"{plant}-{sonar_location}-short-burn-in\",\n",
    "    )\n",
    "    print(f'submitted job with tags: {pipeline_job_run.tags}')\n",
    "    \n",
    "shutil.rmtree(pth)\n",
    "shutil.rmtree(pth_cls)\n",
    "    \n",
    "shutil.rmtree(pth)\n",
    "shutil.rmtree(pth_cls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
